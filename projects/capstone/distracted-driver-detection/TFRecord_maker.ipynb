{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecord maker: from `.jpg` to `.tfrecord`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents how to convert the image data from `.jpg` to `.tfrecord`. The main reference is [KWOT SIN's blog](https://kwotsin.github.io/tech/2017/01/29/tfrecords.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arranging data according to classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create TFRecord files, the dataset has to be arranged into subdirectories, where each one represents the class. In our case, the dataset is already arranged in this way.\n",
    "```\n",
    "drivers_data\n",
    "└── train [22424 images]\n",
    "    ├── c0 安全驾驶 [2489 images]\n",
    "    ├── c1 右手手机打字 [2267 images]\n",
    "    ├── c2 右手打电话 [2317 images]\n",
    "    ├── c3 左手手机打字 [2346 images]\n",
    "    ├── c4 左手打电话 [2326 images]\n",
    "    ├── c5 调收音机 [2312 images]\n",
    "    ├── c6 喝水 [2325 images]\n",
    "    ├── c7 拿后面的东西 [2002 images]\n",
    "    ├── c8 整理头发和化妆 [1911 images]\n",
    "    └── c9 和乘客交谈 [2129 images]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing `.tfrecord` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-slim provides several useful functions that will help us to creat TFRecord file without dig into the low-level TensorFlow. KWOT SIN also compiles necessary functions into `dataset_utils.py` file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from datasets.dataset_utils import _dataset_exists, _get_filenames_and_classes, write_label_file, _convert_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And required arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "#State your dataset directory\n",
    "flags.DEFINE_string('dataset_dir', 'drivers_data', 'String: Your dataset directory')\n",
    "\n",
    "# Proportion of dataset to be used for evaluation\n",
    "flags.DEFINE_float('validation_size', 0.3, 'Float: The proportion of examples in the dataset to be used for validation')\n",
    "\n",
    "# The number of shards to split the dataset into.\n",
    "flags.DEFINE_integer('num_shards', 5, 'Int: Number of shards to split the TFRecord files into')\n",
    "\n",
    "# Seed for repeatability.\n",
    "flags.DEFINE_integer('random_seed', 42, 'Int: Random seed to use for repeatability.')\n",
    "\n",
    "#Output filename for the naming the TFRecord file\n",
    "flags.DEFINE_string('tfrecord_filename', 'drivers', 'String: The output filename to name your TFRecord file')\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the TFRecord files exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============CHECKS==============\n",
    "#Check if there is a tfrecord_filename entered\n",
    "if not FLAGS.tfrecord_filename:\n",
    "    raise ValueError('tfrecord_filename is empty. Please state a tfrecord_filename argument.')\n",
    "\n",
    "#Check if there is a dataset directory entered\n",
    "if not FLAGS.dataset_dir:\n",
    "    raise ValueError('dataset_dir is empty. Please state a dataset_dir argument.')\n",
    "\n",
    "#If the TFRecord files already exist in the directory, then exit without creating the files again\n",
    "if _dataset_exists(dataset_dir = FLAGS.dataset_dir, _NUM_SHARDS = FLAGS.num_shards, output_filename = FLAGS.tfrecord_filename):\n",
    "    print 'Dataset files already exist. Exiting without re-creating them.'\n",
    "    return None\n",
    "#==========END OF CHECKS============"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the `.tfrecord` files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get image filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "photo_filenames, class_names = _get_filenames_and_classes(FLAGS.dataset_dir)  \n",
    "class_names_to_ids = dict(zip(class_names, range(len(class_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the number of validation examples we need\n",
    "num_validation = int(FLAGS.validation_size * len(photo_filenames))\n",
    "\n",
    "# Divide the training datasets into train and test:\n",
    "random.seed(FLAGS.random_seed)\n",
    "random.shuffle(photo_filenames)\n",
    "training_filenames = photo_filenames[num_validation:]\n",
    "validation_filenames = photo_filenames[:num_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Converting image 15697/15697 shard 4\n",
      ">> Converting image 6727/6727 shard 4\n"
     ]
    }
   ],
   "source": [
    "# First, convert the training and validation sets.\n",
    "_convert_dataset('train', training_filenames, class_names_to_ids,\n",
    "                 dataset_dir = FLAGS.dataset_dir,\n",
    "                 tfrecord_filename = FLAGS.tfrecord_filename,\n",
    "                 _NUM_SHARDS = FLAGS.num_shards)\n",
    "_convert_dataset('validation', validation_filenames, class_names_to_ids,\n",
    "                 dataset_dir = FLAGS.dataset_dir,\n",
    "                 tfrecord_filename = FLAGS.tfrecord_filename,\n",
    "                 _NUM_SHARDS = FLAGS.num_shards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally, write the labels file:\n",
    "labels_to_class_names = dict(zip(range(len(class_names)), class_names))\n",
    "write_label_file(labels_to_class_names, FLAGS.dataset_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
