{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.framework.python.ops.variables import get_or_create_global_step\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "\n",
    "from preprocessing.preprocessing_factory import get_preprocessing\n",
    "from nets import nets_factory\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tensorflow.contrib import slim\n",
    "\n",
    "from datasets import dataset_utils\n",
    "from checkpoints_downloader import ckpt_maker\n",
    "from dataset_preparation import get_split, load_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL = 'resnet_v2_50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading resnet_v2_50_2017_04_14.tar.gz 100.0%\n",
      "Successfully downloaded resnet_v2_50_2017_04_14.tar.gz 286441851 bytes.\n",
      "Checkpoint for resnet_v2_50 is ready!\n",
      "File name: checkpoints/resnet_v2_50.ckpt\n"
     ]
    }
   ],
   "source": [
    "checkpoint_file = ckpt_maker(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#================ DATASET INFORMATION ======================\n",
    "#State dataset directory where the tfrecord files are located\n",
    "dataset_dir = '/drivers_data'\n",
    "\n",
    "#State where your log file is at. If it doesn't exist, create it.\n",
    "log_dir = 'log/' + MODEL\n",
    "\n",
    "if not tf.gfile.Exists(log_dir):\n",
    "    tf.gfile.MakeDirs(log_dir)\n",
    "\n",
    "#State the number of classes to predict:\n",
    "num_classes = 10\n",
    "\n",
    "# #State the labels file and read it\n",
    "# labels_file = 'drivers_data/labels.txt'\n",
    "# labels = open(labels_file, 'r')\n",
    "\n",
    "# #Create a dictionary to refer each label to their string name\n",
    "# labels_to_name = {}\n",
    "# for line in labels:\n",
    "#     label, string_name = line.split(':')\n",
    "#     string_name = string_name[:-1] #Remove newline\n",
    "#     labels_to_name[int(label)] = string_name\n",
    "\n",
    "# Create the file pattern of your TFRecord files so that it could be recognized later on\n",
    "# file_pattern = 'drivers_%s_*.tfrecord'\n",
    "file_pattern = 'drivers_{}_*.tfrecord'\n",
    "\n",
    "#Create a dictionary that will help people understand your dataset better. This is required by the Dataset class later.\n",
    "items_to_descriptions = {\n",
    "    'image': 'A 3-channel RGB coloured driver image.',\n",
    "    'label': 'A label from 0 to 9.'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The model for training\n",
    "model_train = nets_factory.get_network_fn(MODEL, num_classes, is_training=True)\n",
    "\n",
    "# The model for evaluation\n",
    "model_eval = nets_factory.get_network_fn(MODEL, num_classes, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# State the image size you're resizing your images to. \n",
    "image_size = model_train.default_image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#================= TRAINING INFORMATION ==================\n",
    "# State the number of epochs to train\n",
    "num_epochs = 30\n",
    "\n",
    "# State your batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Learning rate information and configuration (Up to you to experiment)\n",
    "initial_learning_rate = 0.001\n",
    "learning_rate_decay_factor = 0.7\n",
    "num_epochs_before_decay = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from log/resnet_v2_50/model.ckpt-4565\n",
      "INFO:tensorflow:Epoch 1.0/30\n",
      "INFO:tensorflow:Current Learning Rate: 0.0002401000092504546\n",
      "INFO:tensorflow:Current Streaming Accuracy: 0.0\n",
      "INFO:tensorflow:global step 4567: loss: 0.07189057022333145\n",
      "INFO:tensorflow:global step 4577: loss: 0.28046271204948425\n",
      "INFO:tensorflow:global step 4587: loss: 0.13434793055057526\n",
      "INFO:tensorflow:global step 4597: loss: 0.07863301783800125\n",
      "INFO:tensorflow:global step 4607: loss: 0.36539894342422485\n",
      "INFO:tensorflow:global step 4617: loss: 0.26720091700553894\n",
      "INFO:tensorflow:global step 4627: loss: 0.11038193106651306\n",
      "INFO:tensorflow:global step 4637: loss: 0.2415679693222046\n",
      "INFO:tensorflow:global step 4647: loss: 0.206980362534523\n",
      "INFO:tensorflow:global step 4657: loss: 0.16673707962036133\n",
      "INFO:tensorflow:global step 4667: loss: 0.16701248288154602\n",
      "INFO:tensorflow:global step 4677: loss: 0.21359717845916748\n",
      "INFO:tensorflow:global step 4687: loss: 0.19678214192390442\n",
      "INFO:tensorflow:global step 4697: loss: 0.16472002863883972\n",
      "INFO:tensorflow:global step 4707: loss: 0.09150480479001999\n",
      "INFO:tensorflow:global step 4717: loss: 0.46569231152534485\n",
      "INFO:tensorflow:global step 4727: loss: 0.14719833433628082\n",
      "INFO:tensorflow:global step 4737: loss: 0.17066431045532227\n",
      "INFO:tensorflow:global step 4747: loss: 0.19349686801433563\n",
      "INFO:tensorflow:global step 4757: loss: 0.385652631521225\n",
      "INFO:tensorflow:global step 4767: loss: 0.3975871801376343\n",
      "INFO:tensorflow:global step 4777: loss: 0.29978427290916443\n",
      "INFO:tensorflow:global step 4787: loss: 0.057995982468128204\n",
      "INFO:tensorflow:global step 4797: loss: 0.14841604232788086\n",
      "INFO:tensorflow:global step 4807: loss: 0.38308197259902954\n",
      "INFO:tensorflow:global step 4817: loss: 0.25502970814704895\n",
      "INFO:tensorflow:global step 4827: loss: 0.2752363681793213\n",
      "INFO:tensorflow:global step 4837: loss: 0.17494109272956848\n",
      "INFO:tensorflow:global step 4847: loss: 0.12468529492616653\n",
      "INFO:tensorflow:global step 4857: loss: 0.15184402465820312\n",
      "INFO:tensorflow:global step 4867: loss: 0.47696277499198914\n",
      "INFO:tensorflow:global step 4877: loss: 0.2799190878868103\n",
      "INFO:tensorflow:global step 4887: loss: 0.30075252056121826\n",
      "INFO:tensorflow:global step 4897: loss: 0.36349061131477356\n",
      "INFO:tensorflow:global step 4907: loss: 0.17913387715816498\n",
      "INFO:tensorflow:global step 4917: loss: 0.48441052436828613\n",
      "INFO:tensorflow:global step 4927: loss: 0.18157660961151123\n",
      "INFO:tensorflow:global step 4937: loss: 0.125791996717453\n",
      "INFO:tensorflow:global step 4947: loss: 0.2996135652065277\n",
      "INFO:tensorflow:global step 4957: loss: 0.21809902787208557\n",
      "INFO:tensorflow:global step 4967: loss: 0.18069560825824738\n",
      "INFO:tensorflow:global step 4977: loss: 0.16757071018218994\n",
      "INFO:tensorflow:global step 4987: loss: 0.4484294056892395\n",
      "INFO:tensorflow:global step 4997: loss: 0.1791590303182602\n",
      "INFO:tensorflow:global step 5007: loss: 0.12324529141187668\n",
      "INFO:tensorflow:global step 5017: loss: 0.27258479595184326\n",
      "INFO:tensorflow:global step 5027: loss: 0.48940080404281616\n",
      "INFO:tensorflow:global step 5037: loss: 0.2705276608467102\n",
      "INFO:tensorflow:global step 5047: loss: 0.2205003798007965\n",
      "INFO:tensorflow:Epoch 2.0/30\n",
      "INFO:tensorflow:Current Learning Rate: 0.00016806999337859452\n",
      "INFO:tensorflow:Current Streaming Accuracy: 0.9169005155563354\n",
      "INFO:tensorflow:global step 5057: loss: 0.38343024253845215\n",
      "INFO:tensorflow:global step 5067: loss: 0.12567345798015594\n",
      "INFO:tensorflow:global step 5077: loss: 0.28349190950393677\n",
      "INFO:tensorflow:global step 5087: loss: 0.11505689471960068\n",
      "INFO:tensorflow:global step 5097: loss: 0.3284560441970825\n",
      "INFO:tensorflow:global step 5107: loss: 0.3756462037563324\n",
      "INFO:tensorflow:global step 5117: loss: 0.208953395485878\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as graph:\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    \n",
    "    # creat dataset and load batches\n",
    "    dataset = get_split('train', dataset_dir, file_pattern=file_pattern)\n",
    "    images, _, labels = load_batch(dataset, \n",
    "                                   batch_size=batch_size, \n",
    "                                   MODEL=MODEL, \n",
    "                                   height=image_size, \n",
    "                                   width=image_size, \n",
    "                                   is_training=True)\n",
    "    \n",
    "    num_batches_per_epoch = int(dataset.num_samples / batch_size)\n",
    "    num_steps_per_epoch = num_batches_per_epoch\n",
    "    decay_steps = int(num_epochs_before_decay * num_steps_per_epoch)\n",
    "    \n",
    "    # creat the model\n",
    "    logits, end_points = model_train(images)\n",
    "    \n",
    "    # define scopes to excluded\n",
    "    exclude = ['resnet_v2_50/logits']\n",
    "    variables_to_restore = slim.get_variables_to_restore(exclude=exclude)\n",
    "    \n",
    "    # one-hot-encodeing of the labels\n",
    "    one_hot_labels = slim.one_hot_encoding(labels, dataset.num_classes)\n",
    "    \n",
    "    # calculate loss\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits=logits)\n",
    "    total_loss = tf.losses.get_total_loss()\n",
    "    \n",
    "    # create global step for mornitoring\n",
    "    global_step = get_or_create_global_step()\n",
    "    \n",
    "    # define decaying learning rate\n",
    "    learning_rate = tf.train.exponential_decay(learning_rate=initial_learning_rate, \n",
    "                                               global_step=global_step, \n",
    "                                               decay_steps=decay_steps, \n",
    "                                               decay_rate=learning_rate_decay_factor, \n",
    "                                               staircase=True)\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    \n",
    "    # create training operator\n",
    "    train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "    \n",
    "    # the predictions\n",
    "    probabilities = end_points['predictions']\n",
    "    predictions = tf.argmax(end_points['predictions'], 1)\n",
    "    accuracy, accuracy_update = tf.contrib.metrics.streaming_accuracy(predictions, labels)\n",
    "    metrics_op = tf.group(accuracy_update, probabilities)\n",
    "    \n",
    "    # summaries\n",
    "    tf.summary.scalar('losses/Total_Loss', total_loss)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "    my_summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    # define training step function\n",
    "    def train_step(sess, train_op, global_step):\n",
    "        start_time = time.time()\n",
    "        total_loss, global_step_count, _ = sess.run([train_op, global_step, metrics_op])\n",
    "        time_elapsed = time.time() - start_time\n",
    "        \n",
    "        # logging.info('global step %s: loss: %.4f (%.2f sec/step)', global_step_count, total_loss, time_elapsed)\n",
    "        \n",
    "        return total_loss, global_step_count\n",
    "    \n",
    "    # create saver function to restore variables from a checkpoint file\n",
    "    saver = tf.train.Saver(variables_to_restore)\n",
    "    def restore_fn(sess):\n",
    "        return saver.restore(sess, checkpoint_file)\n",
    "    \n",
    "    sv = tf.train.Supervisor(logdir=log_dir, summary_op=None, init_fn=restore_fn)\n",
    "    \n",
    "    with sv.managed_session() as sess:\n",
    "        for step in range(num_steps_per_epoch * num_epochs):\n",
    "            if step % num_batches_per_epoch == 0:\n",
    "                logging.info('Epoch {}/{}'.format(step/num_batches_per_epoch + 1, num_epochs))\n",
    "                learning_rate_value, accuracy_value = sess.run([learning_rate, accuracy])\n",
    "                logging.info('Current Learning Rate: {}'.format(learning_rate_value))\n",
    "                logging.info('Current Streaming Accuracy: {}'.format(accuracy_value))\n",
    "                \n",
    "            if step % 10 == 0:\n",
    "                loss, step = train_step(sess, train_op, sv.global_step)\n",
    "                summaries = sess.run(my_summary_op)\n",
    "                sv.summary_computed(sess, summaries)\n",
    "                logging.info('global step {}: loss: {}'.format(step, loss))\n",
    "            else:\n",
    "                loss, _ = train_step(sess, train_op, sv.global_step)\n",
    "                \n",
    "        logging.info('Final Loss: {}'.format(loss))\n",
    "        logging.info('Final Accuracy: {}'.format(sess.run(accuracy)))\n",
    "        \n",
    "        logging.info('Training finished! Saving model to disk.')\n",
    "        sv.saver.save(sess, sv.save_path, global_step=sv.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
