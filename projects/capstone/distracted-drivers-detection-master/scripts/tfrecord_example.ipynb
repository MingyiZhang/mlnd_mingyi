{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def int64_feature(values):\n",
    "  \"\"\"Returns a TF-Feature of int64s.\n",
    "\n",
    "  Args:\n",
    "    values: A scalar or list of values.\n",
    "\n",
    "  Returns:\n",
    "    a TF-Feature.\n",
    "  \"\"\"\n",
    "  if not isinstance(values, (tuple, list)):\n",
    "    values = [values]\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "\n",
    "def float_feature(values):\n",
    "    if not isinstance(values, (tuple, list)):\n",
    "        values = [values]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=values))\n",
    "\n",
    "\n",
    "def bytes_feature(values):\n",
    "  \"\"\"Returns a TF-Feature of bytes.\n",
    "\n",
    "  Args:\n",
    "    values: A string.\n",
    "\n",
    "  Returns:\n",
    "    a TF-Feature.\n",
    "  \"\"\"\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [[0 1 2]\n",
      " [3 4 5]]\n",
      "b: narray_0\n",
      "a_raw: b'\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x05\\x00\\x00\\x00'\n",
      "b_raw: b'narray_0'\n",
      "height of a: 2\n",
      "width of a: 3\n",
      "a: [[1 2 3]\n",
      " [4 5 6]]\n",
      "b: narray_1\n",
      "a_raw: b'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x06\\x00\\x00\\x00'\n",
      "b_raw: b'narray_1'\n",
      "height of a: 2\n",
      "width of a: 3\n"
     ]
    }
   ],
   "source": [
    "with tf.python_io.TFRecordWriter('test.tfrecord') as writer:\n",
    "    for i in range(2):\n",
    "        a = np.array([[0, 1, 2], [3, 4, 5]]) + i\n",
    "        a_raw = a.tostring()\n",
    "        h = a.shape[0]\n",
    "        w = a.shape[1]\n",
    "        b = 'narray_{}'.format(i)\n",
    "        b_raw = b.encode()\n",
    "        print('a: {}'.format(a))\n",
    "        print('b: {}'.format(b))\n",
    "        print('a_raw: {}'.format(a_raw))\n",
    "        print('b_raw: {}'.format(b_raw))\n",
    "        print('height of a: {}'.format(h))\n",
    "        print('width of a: {}'.format(w))\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "            feature = {'array/encode': bytes_feature(a_raw),\n",
    "                       'array/height': int64_feature(h), \n",
    "                       'array/width': int64_feature(w), \n",
    "                       'string': bytes_feature(b_raw)})) \n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\ns\\n,\\n\\x0carray/encode\\x12\\x1c\\n\\x1a\\n\\x18\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\n\\x15\\n\\x0carray/height\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x14\\n\\x0barray/width\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x16\\n\\x06string\\x12\\x0c\\n\\n\\n\\x08narray_0'\n",
      "b'\\ns\\n,\\n\\x0carray/encode\\x12\\x1c\\n\\x1a\\n\\x18\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x05\\x00\\x00\\x00\\x06\\x00\\x00\\x00\\n\\x15\\n\\x0carray/height\\x12\\x05\\x1a\\x03\\n\\x01\\x02\\n\\x14\\n\\x0barray/width\\x12\\x05\\x1a\\x03\\n\\x01\\x03\\n\\x16\\n\\x06string\\x12\\x0c\\n\\n\\n\\x08narray_1'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 0\n",
    "for record in tf.python_io.tf_record_iterator('test.tfrecord'):\n",
    "    print(record)\n",
    "    num_samples += 1\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_4:0\", shape=(2, 3), dtype=int32)\n",
      "Tensor(\"Reshape:0\", shape=(), dtype=string)\n",
      "INFO:tensorflow:Starting standard services.\n",
      "INFO:tensorflow:Starting queue runners.\n",
      "INFO:tensorflow:Recording summary at step None.\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "2\n",
      "3\n",
      "b'narray_0'\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "2\n",
      "3\n",
      "b'narray_1'\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as graph:\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    keys_to_features = {\n",
    "        'array/encode': tf.FixedLenFeature([], tf.string),\n",
    "        'array/height': tf.FixedLenFeature([], tf.int64),\n",
    "        'array/width': tf.FixedLenFeature([], tf.int64),\n",
    "        'string': tf.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "    items_to_handlers = {\n",
    "        'array': slim.tfexample_decoder.Tensor('array/encode'),\n",
    "        'height': slim.tfexample_decoder.Tensor('array/height'),\n",
    "        'width': slim.tfexample_decoder.Tensor('array/width'),\n",
    "        'string': slim.tfexample_decoder.Tensor('string')\n",
    "        }\n",
    "    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "    reader = tf.TFRecordReader\n",
    "    dataset = slim.dataset.Dataset(\n",
    "        data_sources = 'test.tfrecord',\n",
    "        decoder = decoder,\n",
    "        reader = reader,\n",
    "        num_samples = 2,\n",
    "        items_to_descriptions = None)\n",
    " \n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "        dataset,\n",
    "        common_queue_capacity = 2,\n",
    "        common_queue_min = 1,\n",
    "        shuffle=False)\n",
    "\n",
    "    array, height, width, string = data_provider.get(['array', 'height', 'width', 'string'])\n",
    "    \n",
    "    array_out = tf.decode_raw(array, tf.int32)\n",
    "    array_out = tf.reshape(array_out, (2, 3))\n",
    "    print(array_out)\n",
    "    print(array)\n",
    "#     array_out = tf.reshape(array_out, [height, width])\n",
    "    \n",
    "    \n",
    "    arrays, heights, widths, strings = tf.train.batch(\n",
    "                        [array_out, height, width, string],\n",
    "                        batch_size=1,\n",
    "                        num_threads=1,\n",
    "                        capacity=2,\n",
    "                        allow_smaller_final_batch = True)\n",
    "\n",
    "    \n",
    "    sv = tf.train.Supervisor(logdir='log_tfrecord_eg')\n",
    "    \n",
    "    with sv.managed_session() as sess:\n",
    "#     with tf.Session() as sess:\n",
    "        for i in range(2):\n",
    "            a, h, w, s = sess.run([arrays, heights, widths, strings])\n",
    "            print(a[0])\n",
    "            print(h[0])\n",
    "            print(w[0])\n",
    "            print(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage.io import imread, imshow\n",
    "import tensorflow as tf\n",
    "from preprocessing.preprocessing_factory import get_preprocessing\n",
    "from nets import nets_factory\n",
    "%matplotlib inline  \n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "from datasets import dataset_utils\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def array_to_tfexample(array_b, class_id, img_b):\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'array/encoded': bytes_feature(array_b),\n",
    "        'array/filename': bytes_feature(img_b),\n",
    "        'array/class/label': int64_feature(class_id)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def array_to_tfrecord(array, class_id, img, writer):\n",
    "    array = array.astype(np.float32)\n",
    "    array_b = array.tostring()\n",
    "    img_b = img.encode()\n",
    "    example = array_to_tfexample(array_b, class_id, img_b)\n",
    "    writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_gap(MODEL, num_classes, dataset_dir, split_name, file_pattern, checkpoints_dir, base_scope, log_dir, tfrecord_name):\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.logging.set_verbosity(tf.logging.INFO)\n",
    "        \n",
    "        # load model\n",
    "        model = nets_factory.get_network_fn(MODEL, num_classes=num_classes, is_training=False)\n",
    "        # get image size\n",
    "        image_size = model.default_image_size\n",
    "        checkpoint_file = ckpt_maker(MODEL, checkpoints_dir=checkpoints_dir)\n",
    "        \n",
    "        dataset = get_split(split_name=split_name, \n",
    "                            dataset_dir=dataset_dir, \n",
    "                            file_pattern=file_pattern, \n",
    "                            file_pattern_for_counting='drivers', \n",
    "                            items_to_descriptions=None)\n",
    "        images, _, labels, image_names = load_batch(\n",
    "            dataset=dataset, \n",
    "            batch_size=1, \n",
    "            MODEL=MODEL, \n",
    "            height=image_size, \n",
    "            width=image_size, \n",
    "            is_training=False)\n",
    "        \n",
    "        _, endpoints = model(images)\n",
    "        \n",
    "        net = endpoints[base_scope]\n",
    "        shape = net.get_shape()\n",
    "        net = tf.layers.average_pooling2d(net, \n",
    "                                          pool_size=[shape[1], shape[2]],\n",
    "                                          strides=1,\n",
    "                                          padding='valid',\n",
    "                                          name='avg_pool')\n",
    "        net = tf.squeeze(net, [1, 2], name='SpatialSqueeze')\n",
    "        \n",
    "        variables_to_restore = slim.get_variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore)\n",
    "        def restore_fn(sess):\n",
    "            return saver.restore(sess, checkpoint_file)\n",
    "        \n",
    "        sv = tf.train.Supervisor(logdir=log_dir, summary_op=None, saver=None, init_fn=restore_fn)\n",
    "    \n",
    "        with sv.managed_session() as sess:\n",
    "            with tf.python_io.TFRecordWriter(tfrecord_name) as writer:\n",
    "                if i in tqdm(range(dataset.num_samples)):\n",
    "                    vec, label, image_name = sess.run([net, labels, image_names])\n",
    "                    array = np.array(vec[0])\n",
    "                    array_class_id = label[0]\n",
    "                    image_name = image_name[0]\n",
    "                    \n",
    "                    array_to_tfrecord(array, array_class_id, image_name, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.python_io.TFRecordWriter('test.tfrecord') as writer:\n",
    "    for i in range(2):\n",
    "        a = np.array([[0, 1, 2], [3, 4, 5]]) + i\n",
    "        a_raw = a.tostring()\n",
    "        h = a.shape[0]\n",
    "        w = a.shape[1]\n",
    "        b = 'narray_{}'.format(i)\n",
    "        b_raw = b.encode()\n",
    "        print('a: {}'.format(a))\n",
    "        print('b: {}'.format(b))\n",
    "        print('a_raw: {}'.format(a_raw))\n",
    "        print('b_raw: {}'.format(b_raw))\n",
    "        print('height of a: {}'.format(h))\n",
    "        print('width of a: {}'.format(w))\n",
    "        example = tf.train.Example(features=tf.train.Features(\n",
    "            feature = {'array/encode': bytes_feature(a_raw),\n",
    "                       'array/height': int64_feature(h), \n",
    "                       'array/width': int64_feature(w), \n",
    "                       'string': bytes_feature(b_raw)})) \n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "resnet_v2_50/conv1\n",
      "112\n",
      "resnet_v2_50/block1/unit_1/bottleneck_v2/shortcut\n",
      "56\n",
      "resnet_v2_50/block1/unit_1/bottleneck_v2/conv1\n",
      "56\n",
      "resnet_v2_50/block1/unit_1/bottleneck_v2/conv2\n",
      "56\n",
      "resnet_v2_50/block1/unit_1/bottleneck_v2/conv3\n",
      "56\n",
      "resnet_v2_50/block1/unit_1/bottleneck_v2\n",
      "56\n",
      "resnet_v2_50/block1/unit_2/bottleneck_v2/conv1\n",
      "56\n",
      "resnet_v2_50/block1/unit_2/bottleneck_v2/conv2\n",
      "56\n",
      "resnet_v2_50/block1/unit_2/bottleneck_v2/conv3\n",
      "56\n",
      "resnet_v2_50/block1/unit_2/bottleneck_v2\n",
      "56\n",
      "resnet_v2_50/block1/unit_3/bottleneck_v2/conv1\n",
      "56\n",
      "resnet_v2_50/block1/unit_3/bottleneck_v2/conv2\n",
      "28\n",
      "resnet_v2_50/block1/unit_3/bottleneck_v2/conv3\n",
      "28\n",
      "resnet_v2_50/block1/unit_3/bottleneck_v2\n",
      "28\n",
      "resnet_v2_50/block1\n",
      "28\n",
      "resnet_v2_50/block2/unit_1/bottleneck_v2/shortcut\n",
      "28\n",
      "resnet_v2_50/block2/unit_1/bottleneck_v2/conv1\n",
      "28\n",
      "resnet_v2_50/block2/unit_1/bottleneck_v2/conv2\n",
      "28\n",
      "resnet_v2_50/block2/unit_1/bottleneck_v2/conv3\n",
      "28\n",
      "resnet_v2_50/block2/unit_1/bottleneck_v2\n",
      "28\n",
      "resnet_v2_50/block2/unit_2/bottleneck_v2/conv1\n",
      "28\n",
      "resnet_v2_50/block2/unit_2/bottleneck_v2/conv2\n",
      "28\n",
      "resnet_v2_50/block2/unit_2/bottleneck_v2/conv3\n",
      "28\n",
      "resnet_v2_50/block2/unit_2/bottleneck_v2\n",
      "28\n",
      "resnet_v2_50/block2/unit_3/bottleneck_v2/conv1\n",
      "28\n",
      "resnet_v2_50/block2/unit_3/bottleneck_v2/conv2\n",
      "28\n",
      "resnet_v2_50/block2/unit_3/bottleneck_v2/conv3\n",
      "28\n",
      "resnet_v2_50/block2/unit_3/bottleneck_v2\n",
      "28\n",
      "resnet_v2_50/block2/unit_4/bottleneck_v2/conv1\n",
      "28\n",
      "resnet_v2_50/block2/unit_4/bottleneck_v2/conv2\n",
      "14\n",
      "resnet_v2_50/block2/unit_4/bottleneck_v2/conv3\n",
      "14\n",
      "resnet_v2_50/block2/unit_4/bottleneck_v2\n",
      "14\n",
      "resnet_v2_50/block2\n",
      "14\n",
      "resnet_v2_50/block3/unit_1/bottleneck_v2/shortcut\n",
      "14\n",
      "resnet_v2_50/block3/unit_1/bottleneck_v2/conv1\n",
      "14\n",
      "resnet_v2_50/block3/unit_1/bottleneck_v2/conv2\n",
      "14\n",
      "resnet_v2_50/block3/unit_1/bottleneck_v2/conv3\n",
      "14\n",
      "resnet_v2_50/block3/unit_1/bottleneck_v2\n",
      "14\n",
      "resnet_v2_50/block3/unit_2/bottleneck_v2/conv1\n",
      "14\n",
      "resnet_v2_50/block3/unit_2/bottleneck_v2/conv2\n",
      "14\n",
      "resnet_v2_50/block3/unit_2/bottleneck_v2/conv3\n",
      "14\n",
      "resnet_v2_50/block3/unit_2/bottleneck_v2\n",
      "14\n",
      "resnet_v2_50/block3/unit_3/bottleneck_v2/conv1\n",
      "14\n",
      "resnet_v2_50/block3/unit_3/bottleneck_v2/conv2\n",
      "14\n",
      "resnet_v2_50/block3/unit_3/bottleneck_v2/conv3\n",
      "14\n",
      "resnet_v2_50/block3/unit_3/bottleneck_v2\n",
      "14\n",
      "resnet_v2_50/block3/unit_4/bottleneck_v2/conv1\n",
      "14\n",
      "resnet_v2_50/block3/unit_4/bottleneck_v2/conv2\n",
      "14\n",
      "resnet_v2_50/block3/unit_4/bottleneck_v2/conv3\n",
      "14\n",
      "resnet_v2_50/block3/unit_4/bottleneck_v2\n",
      "14\n",
      "resnet_v2_50/block3/unit_5/bottleneck_v2/conv1\n",
      "14\n",
      "resnet_v2_50/block3/unit_5/bottleneck_v2/conv2\n",
      "14\n",
      "resnet_v2_50/block3/unit_5/bottleneck_v2/conv3\n",
      "14\n",
      "resnet_v2_50/block3/unit_5/bottleneck_v2\n",
      "14\n",
      "resnet_v2_50/block3/unit_6/bottleneck_v2/conv1\n",
      "14\n",
      "resnet_v2_50/block3/unit_6/bottleneck_v2/conv2\n",
      "7\n",
      "resnet_v2_50/block3/unit_6/bottleneck_v2/conv3\n",
      "7\n",
      "resnet_v2_50/block3/unit_6/bottleneck_v2\n",
      "7\n",
      "resnet_v2_50/block3\n",
      "7\n",
      "resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut\n",
      "7\n",
      "resnet_v2_50/block4/unit_1/bottleneck_v2/conv1\n",
      "7\n",
      "resnet_v2_50/block4/unit_1/bottleneck_v2/conv2\n",
      "7\n",
      "resnet_v2_50/block4/unit_1/bottleneck_v2/conv3\n",
      "7\n",
      "resnet_v2_50/block4/unit_1/bottleneck_v2\n",
      "7\n",
      "resnet_v2_50/block4/unit_2/bottleneck_v2/conv1\n",
      "7\n",
      "resnet_v2_50/block4/unit_2/bottleneck_v2/conv2\n",
      "7\n",
      "resnet_v2_50/block4/unit_2/bottleneck_v2/conv3\n",
      "7\n",
      "resnet_v2_50/block4/unit_2/bottleneck_v2\n",
      "7\n",
      "resnet_v2_50/block4/unit_3/bottleneck_v2/conv1\n",
      "7\n",
      "resnet_v2_50/block4/unit_3/bottleneck_v2/conv2\n",
      "7\n",
      "resnet_v2_50/block4/unit_3/bottleneck_v2/conv3\n",
      "7\n",
      "resnet_v2_50/block4/unit_3/bottleneck_v2\n",
      "7\n",
      "resnet_v2_50/block4\n",
      "7\n",
      "resnet_v2_50/logits\n",
      "1\n",
      "predictions\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as graph:\n",
    "    MODEL = 'resnet_v2_50'\n",
    "    # load model\n",
    "    model = nets_factory.get_network_fn(MODEL, num_classes=10, is_training=False)\n",
    "    # get image size\n",
    "    image_size = model.default_image_size\n",
    "\n",
    "    inputs = tf.placeholder(tf.float32, [None, image_size, image_size, 3], name='input')\n",
    "\n",
    "    _, endpoints = model(inputs)\n",
    "\n",
    "    for k in endpoints:\n",
    "        print(k)\n",
    "        print(endpoints[k].get_shape()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
