{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn package learning note\n",
    "The functions and methods of sklearn package learned from Udacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB\n",
    "Gaussian Naive Bayes progression\n",
    "\n",
    "[`sklearn.naive_bayes.`__GaussianNB__](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)\n",
    "\n",
    "__Example__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "print(clf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing module\n",
    "The [`sklearn.preprocessing`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module includes scaling, centering, normalization, binarization and imputation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder\n",
    "__Example__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# creating sample data\n",
    "sample_data = {'name': ['Ray', 'Adam', 'Jason', 'Varun', 'Xiao'],\n",
    "               'health': ['fit', 'slim', 'obese', 'fit', 'slim'],\n",
    "               'test': ['pass', 'fail', 'fail', 'fail', 'pass']}\n",
    "# storing sample data in the form of a dataframe\n",
    "data = pd.DataFrame(sample_data)\n",
    "# fit the data\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(data['health'])\n",
    "# transform the data into numbers\n",
    "label_encoder.transform(data['health'])\n",
    "## label_encoder.fit_transform(data['health']) also works\n",
    "label_encoder.fit_transform(data['test'])\n",
    "data_n = data.apply(label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoder\n",
    "__Example__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit</th>\n",
       "      <th>obese</th>\n",
       "      <th>slim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit  obese  slim\n",
       "0    1      0     0\n",
       "1    0      0     1\n",
       "2    0      1     0\n",
       "3    1      0     0\n",
       "4    0      0     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data['health'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x3 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = preprocessing.OneHotEncoder() # creating OneHotEncoder object\n",
    "label_encoded_data = label_encoder.fit_transform(data['health'])\n",
    "ohe.fit_transform(label_encoded_data.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 0)\t1.0\n",
      "  (1, 8)\t1.0\n",
      "  (1, 3)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (2, 8)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 8)\t1.0\n",
      "  (3, 6)\t1.0\n",
      "  (3, 0)\t1.0\n",
      "  (4, 9)\t1.0\n",
      "  (4, 7)\t1.0\n",
      "  (4, 2)\t1.0\n"
     ]
    }
   ],
   "source": [
    "ohe = preprocessing.OneHotEncoder()\n",
    "Xt = ohe.fit_transform(data_n)\n",
    "print Xt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data Split\n",
    "For sklearn version 0.17, the package is [sklearn.cross_validation](http://scikit-learn.org/0.17/modules/cross_validation.html)\n",
    "\n",
    "For sklearn version 0.18, the package is [sklearn.model_selection.train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96666666666666667"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "# for version 0.18\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.data.shape, iris.target.shape\n",
    "# output ((150, 4), (150,))\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "# output ((90, 4), (90,))\n",
    "X_test.shape, y_test.shape\n",
    "# output ((60, 4), (60,))\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)                           \n",
    "# output 0.96..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $K$-Fold cross validation\n",
    "split the data into $k$-fold, $1$ for test, $k-1$ for trainning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv = KFold(len(authors), 2, shuffle=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`StratifiedKFold()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics (discrete data)\n",
    "__Metric__: the quantity shows how accurate the predictions from the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "> accuracy = number of correctly identified instances / all instances\n",
    "\n",
    "`sklearn.metric.accuracy_score()` method. [link](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "> A confusion matrix $C$ is such that $C_{ij}$ is equal to the number of observations know to be in group $i$ but predicted to be in group $j$. In `sklearn`, $C_{00}$ is True Negtive (TN), $C_{01}$ is False Positive (FP), $C_{10}$ is False Negtive (FN), $C_{11}$ is True Positive (TP).\n",
    "\n",
    "`sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)`. [link](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall and Precision\n",
    "\n",
    "`sklearn.metrics.recall_score()` [link](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)\n",
    "\n",
    "`sklearn.metrics.precision_score()` [link](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    "\n",
    "> __Recall__: If there are $N$ data gives value $i$, the model predict $N'$ of $N$ is $i$, then Recall = $N'/N$\n",
    "$$\n",
    "\\text{Recall}= \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} = \\frac{C_{ii}}{\\sum_j C_{ij}} .\n",
    "$$\n",
    "__Precision__: If there are $N$ predictions, $N'$ fit the data correctly, then Precision = $N'/N$\n",
    "$$\n",
    "\\text{Precision}= \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} = \\frac{C_{ii}}{\\sum_j C_{ji}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score\n",
    "`sklearn.metrics.f1_score()` [link](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)\n",
    "\n",
    "> F1 = 2  (precision $\\times$ recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric (continuum data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error\n",
    "`sklearn.metrics.mean_absolute_error()` [link](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error\n",
    "`sklearn.metrics.mean_squared_error()` [link](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2 score\n",
    "`sklearn.metrics.r2_score()` [link](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained variance score\n",
    "`sklearn.metrics.explained_variance_score()` [link](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html#sklearn.metrics.explained_variance_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve\n",
    "The Learning Curve functionality from sklearn can help us in this respect. It allows us to study the behavior of our model with respect to the number of data points being considered to understand if our model is performing well or not.\n",
    "```python\n",
    "from sklearn.learning_curve import learning_curve # sklearn 0.17\n",
    "from sklearn.model_selection import learning_curve # sklearn 0.18\n",
    "learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "```\n",
    "1. `estimator` is the model, e.g. `GaussianNB()`.\n",
    "2. `x`: feature; `y`: label.\n",
    "3. `cv` is the cross validation generator, which split the data into train and test, e.g. `KFold()` and `train_test_split()`\n",
    "4. `n_jobs`: if run multiple operations in parallel\n",
    "5. `train_sizes`: number of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
